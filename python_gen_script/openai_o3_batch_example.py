# openai_o3_batch_example.py
"""
OpenAI o3 ëª¨ë¸ì„ ì‚¬ìš©í•œ ë°°ì¹˜ ìš”ì²­ ì˜ˆì‹œ
- o3 ëª¨ë¸ì€ ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ì„ ê°€ì§„ ëª¨ë¸
- ë°°ì¹˜ APIë¥¼ í†µí•´ 50% í• ì¸ëœ ê°€ê²©ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥
- ë³µì¡í•œ ìˆ˜í•™, ì½”ë”©, ê³¼í•™ ë¬¸ì œì— íŠ¹íˆ ê°•í•¨
"""

import json
import time
from datetime import datetime
from typing import List, Dict
from openai import OpenAI
from dotenv import load_dotenv
import os


class OpenAIO3BatchService:
    """OpenAI o3 ëª¨ë¸ ë°°ì¹˜ ì„œë¹„ìŠ¤"""

    def __init__(self, api_key: str):
        """
        ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            api_key: OpenAI API í‚¤
        """
        self.client = OpenAI(api_key=api_key)
        # o3 ëª¨ë¸ ì‚¬ìš© (ê³ ê¸‰ ì¶”ë¡  ëª¨ë¸)
        self.model = "o3-mini"

    def create_o3_batch_requests(self, tasks: List[Dict[str, str]]) -> str:
        """
        o3 ëª¨ë¸ìš© ë°°ì¹˜ ìš”ì²­ ìƒì„±

        Args:
            tasks: ì²˜ë¦¬í•  ì‘ì—… ë¦¬ìŠ¤íŠ¸
                  [{"id": "task1", "prompt": "ë¬¸ì œ ì„¤ëª…", "type": "math/coding/reasoning"}]

        Returns:
            ìƒì„±ëœ JSONL íŒŒì¼ëª…
        """
        batch_requests = []

        for i, task in enumerate(tasks):
            # o3 ëª¨ë¸ì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            messages = [
                {
                    "role": "developer",
                    "content": self._get_system_prompt(task.get("type", "general"))
                },
                {
                    "role": "user",
                    "content": task["prompt"]
                }
            ]

            # o3 ëª¨ë¸ìš© ë°°ì¹˜ ìš”ì²­ êµ¬ì„±
            request = {
                "custom_id": task.get("id", f"task-{i}"),
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": self.model,
                    "messages": messages,
                    "max_completion_tokens": 4000,  # o3 ëª¨ë¸ì€ max_completion_tokens í•„ìˆ˜
                    "reasoning_effort": task.get("effort", "medium"),  # low, medium, high
                    "temperature": 0.7
                }
            }
            batch_requests.append(request)

        # JSONL íŒŒì¼ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"o3_batch_requests_{timestamp}.jsonl"

        with open(filename, 'w', encoding='utf-8') as f:
            for request in batch_requests:
                f.write(json.dumps(request, ensure_ascii=False) + '\n')

        print(f"ğŸ“ ë°°ì¹˜ ìš”ì²­ íŒŒì¼ ìƒì„±: {filename}")
        print(f"   ì´ {len(batch_requests)}ê°œ ìš”ì²­")

        return filename

    def _get_system_prompt(self, task_type: str) -> str:
        """ì‘ì—… ìœ í˜•ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompts = {
            "math": "ë‹¹ì‹ ì€ ìˆ˜í•™ ë¬¸ì œ í•´ê²° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¨ê³„ë³„ë¡œ ë…¼ë¦¬ì ìœ¼ë¡œ ì‚¬ê³ í•˜ì—¬ ì •í™•í•œ ë‹µì„ ì œê³µí•˜ì„¸ìš”.",
            "coding": "ë‹¹ì‹ ì€ í”„ë¡œê·¸ë˜ë° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. íš¨ìœ¨ì ì´ê³  ê°€ë…ì„± ì¢‹ì€ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ìì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.",
            "science": "ë‹¹ì‹ ì€ ê³¼í•™ ì—°êµ¬ìì…ë‹ˆë‹¤. ê³¼í•™ì  ì›ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.",
            "reasoning": "ë‹¹ì‹ ì€ ë…¼ë¦¬ì  ì‚¬ê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²°ë¡ ì„ ë„ì¶œí•˜ì„¸ìš”.",
            "history": "ë‹¹ì‹ ì€ ì—­ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•œ ì‚¬ì‹¤ì„ ë°”íƒ•ìœ¼ë¡œ í¥ë¯¸ë¡­ê²Œ ì„¤ëª…í•˜ì„¸ìš”.",
            "general": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”."
        }
        return prompts.get(task_type, prompts["general"])

    def submit_batch(self, jsonl_file: str, description: str = "o3 ëª¨ë¸ ë°°ì¹˜ ì²˜ë¦¬") -> str:
        """
        ë°°ì¹˜ ì‘ì—… ì œì¶œ

        Args:
            jsonl_file: JSONL íŒŒì¼ ê²½ë¡œ
            description: ë°°ì¹˜ ì‘ì—… ì„¤ëª…

        Returns:
            ë°°ì¹˜ ID
        """
        try:
            # 1. íŒŒì¼ ì—…ë¡œë“œ
            print(f"ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {jsonl_file}")
            with open(jsonl_file, 'rb') as f:
                batch_input_file = self.client.files.create(
                    file=f,
                    purpose="batch"
                )

            print(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {batch_input_file.id}")

            # 2. ë°°ì¹˜ ì‘ì—… ìƒì„±
            print("ğŸš€ ë°°ì¹˜ ì‘ì—… ìƒì„± ì¤‘...")
            batch = self.client.batches.create(
                input_file_id=batch_input_file.id,
                endpoint="/v1/chat/completions",
                completion_window="24h",
                metadata={"description": description}
            )

            print(f"âœ… ë°°ì¹˜ ì‘ì—… ìƒì„± ì™„ë£Œ!")
            print(f"   ë°°ì¹˜ ID: {batch.id}")
            print(f"   ìƒíƒœ: {batch.status}")
            print(f"   ì˜ˆìƒ ì™„ë£Œ: 24ì‹œê°„ ì´ë‚´")

            return batch.id

        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì œì¶œ ì‹¤íŒ¨: {e}")
            return None

    def check_batch_status(self, batch_id: str) -> Dict:
        """ë°°ì¹˜ ìƒíƒœ í™•ì¸"""
        try:
            batch = self.client.batches.retrieve(batch_id)

            status_info = {
                'id': batch.id,
                'status': batch.status,
                'created_at': batch.created_at,
                'completed_at': batch.completed_at,
                'request_counts': batch.request_counts.__dict__ if batch.request_counts else {}
            }

            print(f"ğŸ“Š ë°°ì¹˜ ìƒíƒœ: {batch.status}")
            if batch.request_counts:
                counts = batch.request_counts
                total = counts.total or 0
                completed = counts.completed or 0
                failed = counts.failed or 0

                if total > 0:
                    progress = (completed / total) * 100
                    print(f"   ì§„í–‰ë¥ : {completed}/{total} ({progress:.1f}%)")
                    if failed > 0:
                        print(f"   ì‹¤íŒ¨: {failed}ê°œ")

            return status_info

        except Exception as e:
            print(f"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {}

    def download_results(self, batch_id: str) -> List[Dict]:
        """ë°°ì¹˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±"""
        try:
            batch = self.client.batches.retrieve(batch_id)

            if batch.status != "completed":
                print(f"âš ï¸ ë°°ì¹˜ê°€ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {batch.status}")
                return []

            if not batch.output_file_id:
                print("âŒ ì¶œë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []

            print("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")

            # ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            result_content = self.client.files.content(batch.output_file_id)
            result_text = result_content.content.decode('utf-8')

            # ê²°ê³¼ íŒŒì‹±
            results = []
            for line_num, line in enumerate(result_text.strip().split('\n'), 1):
                if line:
                    try:
                        result_data = json.loads(line)

                        if (result_data.get('response') and
                                result_data['response'].get('status_code') == 200):

                            response_body = result_data['response']['body']
                            content = response_body['choices'][0]['message']['content']

                            # o3 ëª¨ë¸ íŠ¹ì„±: reasoning tokens ì •ë³´ í¬í•¨
                            usage = response_body.get('usage', {})

                            results.append({
                                'custom_id': result_data['custom_id'],
                                'content': content,
                                'usage': {
                                    'prompt_tokens': usage.get('prompt_tokens', 0),
                                    'completion_tokens': usage.get('completion_tokens', 0),
                                    'reasoning_tokens': usage.get('reasoning_tokens', 0),  # o3 íŠ¹ì§•
                                    'total_tokens': usage.get('total_tokens', 0)
                                },
                                'line_number': line_num
                            })
                        else:
                            print(f"âŒ ë¼ì¸ {line_num} ì‹¤íŒ¨: {result_data['custom_id']}")

                    except json.JSONDecodeError as e:
                        print(f"âŒ ë¼ì¸ {line_num} JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

            print(f"âœ… ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ì„±ê³µ")
            return results

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def save_results(self, results: List[Dict], filename: str = None):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"o3_mini_results_{timestamp}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")

            # í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½
            if results:
                total_reasoning_tokens = sum(r['usage']['reasoning_tokens'] for r in results)
                total_completion_tokens = sum(r['usage']['completion_tokens'] for r in results)

                print(f"ğŸ“Š í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½:")
                print(f"   ì¶”ë¡  í† í°: {total_reasoning_tokens:,}")
                print(f"   ì™„ì„± í† í°: {total_completion_tokens:,}")
                print(f"   ì´ ì‘ì—…: {len(results)}ê°œ")

        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")


def create_sample_tasks() -> List[Dict[str, str]]:
    """ìƒ˜í”Œ ì‘ì—…ë“¤ ìƒì„± (ë‹¤ì–‘í•œ ì˜ì—­)"""
    tasks = [
        {
            "id": "math-1",
            "type": "math",
            "effort": "high",
            "prompt": "ë‹¤ìŒ ë°©ì •ì‹ì„ í’€ì–´ì£¼ì„¸ìš”: xÂ³ - 6xÂ² + 11x - 6 = 0. ëª¨ë“  êµ¬í•´ì£¼ì„¸ìš”."
        }
    ]
    return tasks


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ§  OpenAI o3-mini ëª¨ë¸ ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆì‹œ")
    print("=" * 50)

    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')

    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = OpenAIO3BatchService(api_key)

    # ìƒ˜í”Œ ì‘ì—… ìƒì„±
    tasks = create_sample_tasks()
    print(f"ğŸ“‹ ìƒì„±ëœ ì‘ì—… ìˆ˜: {len(tasks)}ê°œ")

    # 1. ë°°ì¹˜ ìš”ì²­ íŒŒì¼ ìƒì„±
    jsonl_file = service.create_o3_batch_requests(tasks)

    # 2. ë°°ì¹˜ ì œì¶œ
    batch_id = service.submit_batch(jsonl_file, "o3 ëª¨ë¸ ë‹¤ì–‘í•œ ì˜ì—­ í…ŒìŠ¤íŠ¸")

    if batch_id:
        print(f"\nğŸ‰ ë°°ì¹˜ ì œì¶œ ì™„ë£Œ!")
        print(f"ë°°ì¹˜ ID: {batch_id}")
        print(f"\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ìƒíƒœ í™•ì¸:")
        print(f"service.check_batch_status('{batch_id}')")
        print(f"\nì™„ë£Œ í›„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ:")
        print(f"results = service.download_results('{batch_id}')")
        print(f"service.save_results(results)")

        # ìƒíƒœ í™•ì¸ ì˜ˆì‹œ (ì²« í•œ ë²ˆë§Œ)
        print(f"\nğŸ“Š í˜„ì¬ ìƒíƒœ í™•ì¸:")
        service.check_batch_status(batch_id)


def check_existing_batch_example():
    """ê¸°ì¡´ ë°°ì¹˜ í™•ì¸ ì˜ˆì‹œ í•¨ìˆ˜"""
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    service = OpenAIO3BatchService(api_key)

    # ì‹¤ì œ ë°°ì¹˜ IDë¡œ êµì²´í•˜ì„¸ìš”
    batch_id = "batch_YOUR_ACTUAL_BATCH_ID_HERE"

    print(f"ğŸ“Š ë°°ì¹˜ {batch_id} ìƒíƒœ í™•ì¸ ì¤‘...")
    status = service.check_batch_status(batch_id)

    if status.get('status') == 'completed':
        print("ğŸ‰ ë°°ì¹˜ ì™„ë£Œ! ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        results = service.download_results(batch_id)

        if results:
            service.save_results(results)
            print(f"âœ… ì´ {len(results)}ê°œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")

            # ìƒ˜í”Œ ê²°ê³¼ ì¶œë ¥
            for i, result in enumerate(results[:2]):  # ì²˜ìŒ 2ê°œë§Œ
                print(f"\n--- ê²°ê³¼ {i + 1}: {result['custom_id']} ---")
                print(f"ë‚´ìš©: {result['content'][:200]}...")
                print(f"ì¶”ë¡  í† í°: {result['usage']['reasoning_tokens']}")


if __name__ == "__main__":
    main()

    # ê¸°ì¡´ ë°°ì¹˜ í™•ì¸ì„ ì›í•  ê²½ìš° ì£¼ì„ í•´ì œ
    # check_existing_batch_example()