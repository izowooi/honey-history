# openai_batch_service.py
"""
OpenAI Batch API ì—°ë™ ì„œë¹„ìŠ¤ (Simple Version)
"""

import json
import re
from typing import Dict, List, Optional
from openai import OpenAI
from dotenv import load_dotenv
import os


class OpenAIBatchService:
    """OpenAI Batch API ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, api_key: str, model: str = "gpt-4.1-nano-2025-04-14"):
        """
        OpenAI Batch ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            api_key: OpenAI API í‚¤
            model: ì‚¬ìš©í•  ëª¨ë¸ëª…
        """
        self.client = OpenAI(api_key=api_key)
        self.model = model

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = (
            "ë‹¹ì‹ ì€ ì„¸ê³„ì‚¬ì— ì •í†µí•œ í•™ìì´ì ìŠ¤í† ë¦¬í…”ëŸ¬ì…ë‹ˆë‹¤. "
            "ë…ìê°€ ëª°ì…í•  ìˆ˜ ìˆë„ë¡ ìƒìƒí•˜ê³  í¥ë¯¸ë¡œìš´ ì„œìˆ ì„ ì‚¬ìš©í•˜ì„¸ìš”."
        )

    def upload_batch_file(self, file_path: str = "batchinput.jsonl") -> str:
        """
        ë°°ì¹˜ íŒŒì¼ ì—…ë¡œë“œ

        Args:
            file_path: ì—…ë¡œë“œí•  JSONL íŒŒì¼ ê²½ë¡œ

        Returns:
            file_id: ì—…ë¡œë“œëœ íŒŒì¼ ID
        """
        try:
            print(f"ğŸ“¤ ë°°ì¹˜ íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {file_path}")

            batch_input_file = self.client.files.create(
                file=open(file_path, "rb"),
                purpose="batch"
            )

            print(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! File ID: {batch_input_file.id}")
            return batch_input_file.id

        except Exception as e:
            print(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def create_batch_job(self, file_id: str, description: str = "History content generation") -> str:
        """
        ë°°ì¹˜ ì‘ì—… ìƒì„±

        Args:
            file_id: ì—…ë¡œë“œëœ íŒŒì¼ ID
            description: ë°°ì¹˜ ì‘ì—… ì„¤ëª…

        Returns:
            batch_id: ë°°ì¹˜ ì‘ì—… ID
        """
        try:
            print(f"ğŸš€ ë°°ì¹˜ ì‘ì—… ìƒì„± ì¤‘...")

            batch = self.client.batches.create(
                input_file_id=file_id,
                endpoint="/v1/chat/completions",
                completion_window="24h",
                metadata={
                    "description": description
                }
            )

            print(f"âœ… ë°°ì¹˜ ì‘ì—… ìƒì„± ì™„ë£Œ!")
            print(f"   Batch ID: {batch.id}")
            print(f"   ìƒíƒœ: {batch.status}")
            print(f"   ì„¤ëª…: {description}")

            return batch.id

        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì‘ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def check_batch_status(self, batch_id: str) -> Dict:
        """
        ë°°ì¹˜ ìƒíƒœ ì¡°íšŒ

        Args:
            batch_id: ë°°ì¹˜ ì‘ì—… ID

        Returns:
            ë°°ì¹˜ ìƒíƒœ ì •ë³´
        """
        try:
            batch = self.client.batches.retrieve(batch_id)

            status_info = {
                'id': batch.id,
                'status': batch.status,
                'created_at': batch.created_at,
                'completed_at': batch.completed_at,
                'failed_at': batch.failed_at,
                'output_file_id': batch.output_file_id,
                'error_file_id': batch.error_file_id,
                'request_counts': batch.request_counts.__dict__ if batch.request_counts else {},
                'metadata': batch.metadata
            }

            print(f"ğŸ“Š ë°°ì¹˜ ìƒíƒœ: {batch.status}")
            if batch.request_counts:
                counts = batch.request_counts
                print(f"   ì§„í–‰ë¥ : {counts.completed}/{counts.total} ì™„ë£Œ")
                if counts.failed > 0:
                    print(f"   ì‹¤íŒ¨: {counts.failed}ê°œ")

            return status_info

        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def download_results(self, batch_id: str, output_file: str = None) -> List[Dict]:
        """
        ë°°ì¹˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ

        Args:
            batch_id: ë°°ì¹˜ ì‘ì—… ID
            output_file: ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ëª… (ì„ íƒì‚¬í•­)

        Returns:
            ì²˜ë¦¬ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ë°°ì¹˜ ìƒíƒœ í™•ì¸
            batch = self.client.batches.retrieve(batch_id)

            if batch.status != "completed":
                print(f"âš ï¸ ë°°ì¹˜ê°€ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ: {batch.status}")
                return []

            if not batch.output_file_id:
                print("âŒ ì¶œë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []

            print(f"ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")

            # ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            result_file_response = self.client.files.content(batch.output_file_id)
            result_content = result_file_response.content.decode('utf-8')

            # íŒŒì¼ë¡œ ì €ì¥ (ì˜µì…˜)
            if output_file:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(result_content)
                print(f"ğŸ’¾ ì›ë³¸ ê²°ê³¼ ì €ì¥: {output_file}")

            # ê²°ê³¼ íŒŒì‹±
            results = []
            for line_num, line in enumerate(result_content.strip().split('\n'), 1):
                if line:
                    try:
                        result_data = json.loads(line)

                        # ì„±ê³µí•œ ìš”ì²­ë§Œ ì²˜ë¦¬
                        if (result_data.get('response') and
                                result_data['response'].get('status_code') == 200):

                            content = result_data['response']['body']['choices'][0]['message']['content']
                            parsed_content = self._parse_response(content)

                            results.append({
                                'custom_id': result_data['custom_id'],
                                'content': parsed_content,
                                'line_number': line_num
                            })
                        else:
                            # ì‹¤íŒ¨í•œ ìš”ì²­ ë¡œê¹…
                            print(f"âŒ ë¼ì¸ {line_num} ìš”ì²­ ì‹¤íŒ¨: {result_data['custom_id']}")
                            if 'error' in result_data:
                                print(f"   ì—ëŸ¬: {result_data['error']}")

                    except json.JSONDecodeError as e:
                        print(f"âŒ ë¼ì¸ {line_num} JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

            print(f"âœ… ê²°ê³¼ íŒŒì‹± ì™„ë£Œ: {len(results)}ê°œ ì„±ê³µ")
            return results

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def save_processed_results(self, results: List[Dict], filename: str = None) -> str:
        """
        íŒŒì‹±ëœ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥

        Args:
            results: íŒŒì‹±ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            filename: ì €ì¥í•  íŒŒì¼ëª…

        Returns:
            ì €ì¥ëœ íŒŒì¼ëª…
        """
        if not filename:
            from datetime import datetime
            filename = f"processed_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ì²˜ë¦¬ëœ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def process_batch_complete(self, file_path: str = "batchinput.jsonl",
                               description: str = "History content generation") -> str:
        """
        ë°°ì¹˜ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (ì—…ë¡œë“œ + ìƒì„±)

        Args:
            file_path: JSONL íŒŒì¼ ê²½ë¡œ
            description: ë°°ì¹˜ ì„¤ëª…

        Returns:
            batch_id: ìƒì„±ëœ ë°°ì¹˜ ID
        """
        print("ğŸ¯ ë°°ì¹˜ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        file_id = self.upload_batch_file(file_path)
        if not file_id:
            return None

        # 2. ë°°ì¹˜ ì‘ì—… ìƒì„±
        batch_id = self.create_batch_job(file_id, description)
        if not batch_id:
            return None

        print(f"\nğŸ‰ ë°°ì¹˜ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        print(f"ë°°ì¹˜ ID: {batch_id}")
        print(f"ìƒíƒœ í™•ì¸: service.check_batch_status('{batch_id}')")
        print(f"ê²°ê³¼ ë‹¤ìš´ë¡œë“œ: service.download_results('{batch_id}')")

        return batch_id

    def _parse_response(self, content: str) -> Dict[str, str]:
        """OpenAI ì‘ë‹µ íŒŒì‹± (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)"""
        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            content = re.sub(r'```json\n?', '', content)
            content = re.sub(r'```\n?', '', content)

            parsed = json.loads(content)

            return {
                'simple': parsed.get('simple', ''),
                'detail': parsed.get('detail', ''),
                'year': parsed.get('year', '')
            }

        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._extract_from_text(content)

    def _create_user_prompt(self, topic: str, date: str = "") -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        date_info = f"<DATE>{date}</DATE>\n" if date else ""

        prompt = f'''{date_info}"{topic}"ì— ëŒ€í•´ ë‘ ê°€ì§€ ë²„ì „ì˜ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¡°ê±´
â€¢ ì²« ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë‚ ì§œì˜ ì˜ë¯¸ë¥¼ í¬í•¨í•˜ê³ , AIê°€ ì°¾ì•„ë‚¸ ì—°ë„ì™€ <DATE>ë¥¼ í™œìš©í•´ ë‹¤ì–‘í•˜ê²Œ ì‹œì‘í•˜ì„¸ìš”. 
 ì˜ˆ: "1885ë…„ 7ì›” 6ì¼ì˜ OOì—ì„œëŠ”â€¦", "1832ë…„ 7ì›” 6ì¼ì˜ OOì—ì„œëŠ”â€¦", "ë°”ë¡œ ì˜¤ëŠ˜(7ì›” 6ì¼), â€¦", "1885ë…„ 7ì›” 6ì¼â€¦". 
â€¢ ë²ˆí˜¸, ê¸€ë¨¸ë¦¬í‘œ, í•˜ì´í”ˆì„ ì ˆëŒ€ ì“°ì§€ ë§ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ìœ¼ë¡œë§Œ ì„œìˆ í•˜ì„¸ìš”. 
â€¢ ì ì ˆí•œ ì´ëª¨ì§€ë¥¼ ì„ì–´ í¥ë¯¸ë¥¼ ë†’ì—¬ì£¼ì„¸ìš”. 
â€¢ ì²« ë²ˆì§¸ ë²„ì „ì€ ì´ˆë“±í•™ìƒ ëˆˆë†’ì´ì— ë§ì¶° 300ì ë‚´ì™¸ë¡œ ì§§ê³  ê°„ë‹¨í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”. 
â€¢ ë‘ ë²ˆì§¸ ë²„ì „ì€ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ìœ¼ë¡œ 1500ì ë‚´ì™¸ì´ë©° ë°°ê²½Â·ì „ê°œÂ·ì˜í–¥ê¹Œì§€ ê¹Šì´ ìˆê²Œ ë‹¤ë¤„ ì£¼ì„¸ìš”. 
â€¢ ìµœì¢… ì¶œë ¥ì€ ì•„ë˜ JSON í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ì§€ì¼œ ì£¼ì„¸ìš”(í°ë”°ì˜´í‘œ, ì¤„ë°”ê¿ˆ ìœ ì§€).

{{
 "simple": "<300ì ë‚´ì™¸ ë¬¸ë‹¨>",
 "detail": "<1500ì ë‚´ì™¸ ë¬¸ë‹¨>",
 "year": "<AIê°€ ì°¾ì•„ë‚¸ ì—°ë„>",
}}'''

        return prompt

    def _extract_from_text(self, content: str) -> Dict[str, str]:
        """í…ìŠ¤íŠ¸ì—ì„œ simple/detail ì¶”ì¶œ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)"""
        try:
            simple_pattern = r'"simple":\s*"([^"]*(?:\\.[^"]*)*)"'
            detail_pattern = r'"detail":\s*"([^"]*(?:\\.[^"]*)*)"'
            year_pattern = r'"year":\s*"([^"]*)"'

            simple_match = re.search(simple_pattern, content, re.DOTALL)
            detail_match = re.search(detail_pattern, content, re.DOTALL)
            year_match = re.search(year_pattern, content)

            simple_text = simple_match.group(1) if simple_match else 'ì¶”ì¶œ ì‹¤íŒ¨'
            detail_text = detail_match.group(1) if detail_match else 'ì¶”ì¶œ ì‹¤íŒ¨'
            year_text = year_match.group(1) if year_match else 'ì¶”ì¶œ ì‹¤íŒ¨'

            simple_text = simple_text.replace('\\"', '"').replace('\\n', '\n')
            detail_text = detail_text.replace('\\"', '"').replace('\\n', '\n')
            year_text = year_text.replace('\\"', '"').replace('\\n', '\n')

            return {
                'simple': simple_text,
                'detail': detail_text,
                'year': year_text
            }

        except Exception as e:
            print(f"âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                'simple': 'ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨',
                'detail': 'ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨',
                'year': 'ì—°ë„ ì¶”ì¶œ ì‹¤íŒ¨'
            }


def test_batch_status():
    """ë°°ì¹˜ ìƒíƒœ í™•ì¸ í…ŒìŠ¤íŠ¸"""
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')

    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = OpenAIBatchService(api_key)

    # ì—¬ê¸°ì— ì‹¤ì œ ë°°ì¹˜ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”
    batch_id = "batch_685437e7c1988190bebb1a90ba6f06b8"

    print(f"ğŸ“Š ë°°ì¹˜ {batch_id} ìƒíƒœ í™•ì¸ ì¤‘...")
    status = service.check_batch_status(batch_id)

    if status.get('status') == 'completed':
        print("ğŸ‰ ë°°ì¹˜ ì™„ë£Œ! ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        results = service.download_results(batch_id)

        if results:
            # ê²°ê³¼ ì €ì¥
            saved_file = service.save_processed_results(results)
            print(f"âœ… ì´ {len(results)}ê°œ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ")
    else:
        print(f"\nğŸ“‹ ë°°ì¹˜ ìƒíƒœ ìƒì„¸ ì •ë³´:")
        print("-" * 50)
        print(f"ë°°ì¹˜ ID: {status.get('id', 'N/A')}")
        print(f"ìƒíƒœ: {status.get('status', 'N/A')}")
        print(f"ìƒì„± ì‹œê°„: {status.get('created_at', 'N/A')}")
        print(f"ì™„ë£Œ ì‹œê°„: {status.get('completed_at', 'N/A')}")
        print(f"ì‹¤íŒ¨ ì‹œê°„: {status.get('failed_at', 'N/A')}")
        print(f"ì¶œë ¥ íŒŒì¼ ID: {status.get('output_file_id', 'N/A')}")
        print(f"ì—ëŸ¬ íŒŒì¼ ID: {status.get('error_file_id', 'N/A')}")
        
        # ìš”ì²­ ì¹´ìš´íŠ¸ ì •ë³´
        request_counts = status.get('request_counts', {})
        if request_counts:
            print(f"\nğŸ“Š ìš”ì²­ ì²˜ë¦¬ í˜„í™©:")
            print(f"  ì´ ìš”ì²­ ìˆ˜: {request_counts.get('total', 0)}")
            print(f"  ì™„ë£Œëœ ìš”ì²­: {request_counts.get('completed', 0)}")
            print(f"  ì‹¤íŒ¨í•œ ìš”ì²­: {request_counts.get('failed', 0)}")
            print(f"  ì§„í–‰ë¥ : {request_counts.get('completed', 0)}/{request_counts.get('total', 0)}")
        
        # ë©”íƒ€ë°ì´í„° ì •ë³´
        metadata = status.get('metadata', {})
        if metadata:
            print(f"\nğŸ·ï¸ ë©”íƒ€ë°ì´í„°:")
            for key, value in metadata.items():
                print(f"  {key}: {value}")
        
        print(f"\nâ³ ë°°ì¹˜ê°€ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

def test_batch_service():
    """ë°°ì¹˜ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ OpenAI Batch ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")

    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')

    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = OpenAIBatchService(api_key)

    # ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±
    # print("\nğŸ“ ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„± ì¤‘...")
    # create_batch_input_file(service)

    # ë°©ë²• 1: ì „ì²´ í”„ë¡œì„¸ìŠ¤ í•œ ë²ˆì—
    print("\n=== ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ===")
    batch_id = service.process_batch_complete("batchinput.jsonl")

    if batch_id:
        print(f"\në°°ì¹˜ IDê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {batch_id}")
        print("ì´ì œ ì£¼ê¸°ì ìœ¼ë¡œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”:")
        print(f"service.check_batch_status('{batch_id}')")

    # 3. ìƒíƒœ í™•ì¸ (ë‚˜ì¤‘ì— ì‹¤í–‰)
    if batch_id:
        service.check_batch_status(batch_id)


def create_batch_input_file(service: OpenAIBatchService, file_path: str = "batchinput.jsonl"):
    """
    ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±
    
    Args:
        service: OpenAIBatchService ì¸ìŠ¤í„´ìŠ¤
        file_path: ìƒì„±í•  íŒŒì¼ ê²½ë¡œ
    """
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì œëª©ê³¼ ë‚ ì§œ)
    test_data = [
        {"title": "ê´€ë™ ëŒ€ì§€ì§„", "date": "09-01"},
        {"title": "ëŸ°ë˜ ëŒ€í™”ì¬", "date": "09-02"}
    ]
    
    # ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    existing_lines = []
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                existing_lines = f.readlines()
            print(f"ğŸ“‚ ê¸°ì¡´ íŒŒì¼ ë°œê²¬: {len(existing_lines)}ê°œ ìš”ì²­")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # ìƒˆë¡œìš´ ìš”ì²­ë“¤ ìƒì„±
    new_requests = []
    start_id = len(existing_lines) + 1
    
    for i, data in enumerate(test_data, start_id):
        title = data["title"]
        date = data["date"]
        
        # custom_id ìƒì„± (request-0901 í˜•íƒœ)
        custom_id = f"request-{date.replace('-', '')}"
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_content = service.system_prompt
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±
        user_content = service._create_user_prompt(title, date)
        
        # JSONL í˜•ì‹ìœ¼ë¡œ ìš”ì²­ ìƒì„±
        request = {
            "custom_id": custom_id,
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": service.model,
                "messages": [
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ],
                "max_tokens": 2000
            }
        }
        
        new_requests.append(request)
        print(f"ğŸ“ ìš”ì²­ ìƒì„±: {custom_id} - {title}")
    
    # íŒŒì¼ì— ì“°ê¸° (ê¸°ì¡´ ë‚´ìš© + ìƒˆë¡œìš´ ë‚´ìš©)
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            # ê¸°ì¡´ ë‚´ìš© ì“°ê¸°
            for line in existing_lines:
                f.write(line)
            
            # ìƒˆë¡œìš´ ë‚´ìš© ì“°ê¸°
            for request in new_requests:
                f.write(json.dumps(request, ensure_ascii=False) + '\n')
        
        total_requests = len(existing_lines) + len(new_requests)
        print(f"âœ… ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„± ì™„ë£Œ: {file_path}")
        print(f"   - ê¸°ì¡´ ìš”ì²­: {len(existing_lines)}ê°œ")
        print(f"   - ìƒˆ ìš”ì²­: {len(new_requests)}ê°œ")
        print(f"   - ì´ ìš”ì²­: {total_requests}ê°œ")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")


def check_existing_batch():
    """ê¸°ì¡´ ë°°ì¹˜ ìƒíƒœ í™•ì¸ ì˜ˆì œ"""
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    service = OpenAIBatchService(api_key)

    # ì—¬ê¸°ì— ì‹¤ì œ ë°°ì¹˜ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”
    batch_id = "batch_YOUR_BATCH_ID_HERE"

    print(f"ğŸ“Š ë°°ì¹˜ {batch_id} ìƒíƒœ í™•ì¸ ì¤‘...")
    status = service.check_batch_status(batch_id)

    if status.get('status') == 'completed':
        print("ğŸ‰ ë°°ì¹˜ ì™„ë£Œ! ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        results = service.download_results(batch_id)

        if results:
            # ê²°ê³¼ ì €ì¥
            saved_file = service.save_processed_results(results)
            print(f"âœ… ì´ {len(results)}ê°œ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ")


if __name__ == "__main__":
    # test_batch_service()
    test_batch_status()