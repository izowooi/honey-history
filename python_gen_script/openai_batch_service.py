# openai_batch_service.py
"""
OpenAI Batch API ì—°ë™ ì„œë¹„ìŠ¤ (Simple Version)
"""

import json
import re
from typing import Dict, List, Optional
from openai import OpenAI
from dotenv import load_dotenv
import os


class OpenAIBatchService:
    """OpenAI Batch API ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, api_key: str, model: str = "gpt-4.1-nano-2025-04-14"):
        """
        OpenAI Batch ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            api_key: OpenAI API í‚¤
            model: ì‚¬ìš©í•  ëª¨ë¸ëª…
        """
        self.client = OpenAI(api_key=api_key)
        self.model = model

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = (
            """ì—­í• :
            - ë³µì¡í•œ ì—­ì‚¬ë¥¼ í¥ë¯¸ì§„ì§„í•œ ì´ì•¼ê¸°ë¡œ í’€ì–´ë‚´ëŠ” ì—­ì‚¬ í•´ì„¤ê°€
            - ì–´ë¦°ì´ë¶€í„° ì„±ì¸ê¹Œì§€ ëª¨ë“  ì—°ë ¹ì¸µì´ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…í•˜ëŠ” êµìœ¡ì
            - ê³¼ê±°ì™€ í˜„ì¬ë¥¼ ì—°ê²°í•˜ì—¬ ì—­ì‚¬ì˜ ì˜ë¯¸ë¥¼ ì°¾ì•„ì£¼ëŠ” ì•ˆë‚´ì

            ëª©í‘œ:
            - ë…ìê°€ "ì™€, ì´ëŸ° ì¼ì´ ìˆì—ˆêµ¬ë‚˜!"ë¼ê³  ê°íƒ„í•˜ê²Œ ë§Œë“¤ê¸°
            - ì—­ì‚¬ì  ì‚¬ì‹¤ì„ ì •í™•í•˜ë©´ì„œë„ ì¬ë¯¸ìˆê²Œ ì „ë‹¬í•˜ê¸°
            - ê·¸ ì‹œëŒ€ì˜ ìƒí™©ê³¼ ê°ì •ì„ ìƒìƒí•˜ê²Œ ëŠë‚„ ìˆ˜ ìˆê²Œ í•˜ê¸°
            """
        )

    def upload_batch_file(self, file_path: str = "batchinput.jsonl") -> str:
        """
        ë°°ì¹˜ íŒŒì¼ ì—…ë¡œë“œ

        Args:
            file_path: ì—…ë¡œë“œí•  JSONL íŒŒì¼ ê²½ë¡œ

        Returns:
            file_id: ì—…ë¡œë“œëœ íŒŒì¼ ID
        """
        try:
            print(f"ğŸ“¤ ë°°ì¹˜ íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {file_path}")

            batch_input_file = self.client.files.create(
                file=open(file_path, "rb"),
                purpose="batch"
            )

            print(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! File ID: {batch_input_file.id}")
            return batch_input_file.id

        except Exception as e:
            print(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def create_batch_job(self, file_id: str, description: str = "History content generation") -> str:
        """
        ë°°ì¹˜ ì‘ì—… ìƒì„±

        Args:
            file_id: ì—…ë¡œë“œëœ íŒŒì¼ ID
            description: ë°°ì¹˜ ì‘ì—… ì„¤ëª…

        Returns:
            batch_id: ë°°ì¹˜ ì‘ì—… ID
        """
        try:
            print(f"ğŸš€ ë°°ì¹˜ ì‘ì—… ìƒì„± ì¤‘...")

            batch = self.client.batches.create(
                input_file_id=file_id,
                endpoint="/v1/chat/completions",
                completion_window="24h",
                metadata={
                    "description": description
                }
            )

            print(f"âœ… ë°°ì¹˜ ì‘ì—… ìƒì„± ì™„ë£Œ!")
            print(f"   Batch ID: {batch.id}")
            print(f"   ìƒíƒœ: {batch.status}")
            print(f"   ì„¤ëª…: {description}")

            return batch.id

        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì‘ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def check_batch_status(self, batch_id: str) -> Dict:
        """
        ë°°ì¹˜ ìƒíƒœ ì¡°íšŒ

        Args:
            batch_id: ë°°ì¹˜ ì‘ì—… ID

        Returns:
            ë°°ì¹˜ ìƒíƒœ ì •ë³´
        """
        try:
            batch = self.client.batches.retrieve(batch_id)

            status_info = {
                'id': batch.id,
                'status': batch.status,
                'created_at': batch.created_at,
                'completed_at': batch.completed_at,
                'failed_at': batch.failed_at,
                'output_file_id': batch.output_file_id,
                'error_file_id': batch.error_file_id,
                'request_counts': batch.request_counts.__dict__ if batch.request_counts else {},
                'metadata': batch.metadata
            }

            print(f"ğŸ“Š ë°°ì¹˜ ìƒíƒœ: {batch.status}")
            if batch.request_counts:
                counts = batch.request_counts
                print(f"   ì§„í–‰ë¥ : {counts.completed}/{counts.total} ì™„ë£Œ")
                if counts.failed > 0:
                    print(f"   ì‹¤íŒ¨: {counts.failed}ê°œ")

            return status_info

        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def download_results(self, batch_id: str, output_file: str = None) -> List[Dict]:
        """
        ë°°ì¹˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ

        Args:
            batch_id: ë°°ì¹˜ ì‘ì—… ID
            output_file: ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ëª… (ì„ íƒì‚¬í•­)

        Returns:
            ì²˜ë¦¬ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ë°°ì¹˜ ìƒíƒœ í™•ì¸
            batch = self.client.batches.retrieve(batch_id)

            if batch.status != "completed":
                print(f"âš ï¸ ë°°ì¹˜ê°€ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ: {batch.status}")
                return []

            if not batch.output_file_id:
                print("âŒ ì¶œë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []

            print(f"ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")

            # ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            result_file_response = self.client.files.content(batch.output_file_id)
            result_content = result_file_response.content.decode('utf-8')

            # íŒŒì¼ë¡œ ì €ì¥ (ì˜µì…˜)
            if output_file:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(result_content)
                print(f"ğŸ’¾ ì›ë³¸ ê²°ê³¼ ì €ì¥: {output_file}")

            # ê²°ê³¼ íŒŒì‹±
            results = []
            for line_num, line in enumerate(result_content.strip().split('\n'), 1):
                if line:
                    try:
                        result_data = json.loads(line)

                        # ì„±ê³µí•œ ìš”ì²­ë§Œ ì²˜ë¦¬
                        if (result_data.get('response') and
                                result_data['response'].get('status_code') == 200):

                            content = result_data['response']['body']['choices'][0]['message']['content']
                            parsed_content = self._parse_response(content)

                            results.append({
                                'custom_id': result_data['custom_id'],
                                'content': parsed_content,
                                'line_number': line_num
                            })
                        else:
                            # ì‹¤íŒ¨í•œ ìš”ì²­ ë¡œê¹…
                            print(f"âŒ ë¼ì¸ {line_num} ìš”ì²­ ì‹¤íŒ¨: {result_data['custom_id']}")
                            if 'error' in result_data:
                                print(f"   ì—ëŸ¬: {result_data['error']}")

                    except json.JSONDecodeError as e:
                        print(f"âŒ ë¼ì¸ {line_num} JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

            print(f"âœ… ê²°ê³¼ íŒŒì‹± ì™„ë£Œ: {len(results)}ê°œ ì„±ê³µ")
            return results

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def save_processed_results(self, results: List[Dict], filename: str = None) -> str:
        """
        íŒŒì‹±ëœ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥

        Args:
            results: íŒŒì‹±ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            filename: ì €ì¥í•  íŒŒì¼ëª…

        Returns:
            ì €ì¥ëœ íŒŒì¼ëª…
        """
        if not filename:
            from datetime import datetime
            filename = f"processed_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ì²˜ë¦¬ëœ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def process_batch_complete(self, file_path: str = "batchinput.jsonl",
                               description: str = "History content generation") -> str:
        """
        ë°°ì¹˜ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (ì—…ë¡œë“œ + ìƒì„±)

        Args:
            file_path: JSONL íŒŒì¼ ê²½ë¡œ
            description: ë°°ì¹˜ ì„¤ëª…

        Returns:
            batch_id: ìƒì„±ëœ ë°°ì¹˜ ID
        """
        print("ğŸ¯ ë°°ì¹˜ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        file_id = self.upload_batch_file(file_path)
        if not file_id:
            return None

        # 2. ë°°ì¹˜ ì‘ì—… ìƒì„±
        batch_id = self.create_batch_job(file_id, description)
        if not batch_id:
            return None

        print(f"\nğŸ‰ ë°°ì¹˜ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        print(f"ë°°ì¹˜ ID: {batch_id}")
        print(f"ìƒíƒœ í™•ì¸: service.check_batch_status('{batch_id}')")
        print(f"ê²°ê³¼ ë‹¤ìš´ë¡œë“œ: service.download_results('{batch_id}')")

        return batch_id

    def _parse_response(self, content: str) -> Dict[str, str]:
        """OpenAI ì‘ë‹µ íŒŒì‹± (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)"""
        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            content = re.sub(r'```json\n?', '', content)
            content = re.sub(r'```\n?', '', content)

            parsed = json.loads(content)

            return {
                'simple': parsed.get('simple', ''),
                'detail': parsed.get('detail', ''),
                'year': parsed.get('year', '')
            }

        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._extract_from_text(content)

    def _create_user_prompt(self, topic: str, date: str = "") -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        date_info = f"<DATE>{date}</DATE>\n" if date else ""

        prompt = f'''{date_info}ì˜¤ëŠ˜ {date}ì— ì¼ì–´ë‚œ ì—­ì‚¬ì  ì‚¬ê±´ ë˜ëŠ” ì¸ë¬¼ì— ëŒ€í•´ "{topic}"ë¥¼ ì†Œì¬ë¡œ ë‘ ê°€ì§€ ë²„ì „ì˜ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ğŸ“ ì‘ì„± ì›ì¹™
- ë§ˆì¹˜ ê·¸ í˜„ì¥ì— ìˆì—ˆë˜ ê²ƒì²˜ëŸ¼ ìƒìƒí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”
- ë‹¹ì‹œ ì‚¬ëŒë“¤ì˜ ê°ì •ê³¼ ìƒí™©ì„ ìƒìƒí•  ìˆ˜ ìˆê²Œ ë¬˜ì‚¬í•˜ì„¸ìš”  
- í˜„ì¬ ìš°ë¦¬ ì‚¶ê³¼ì˜ ì—°ê´€ì„±ì´ë‚˜ êµí›ˆë„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ì„¸ìš”
- ë²ˆí˜¸ë‚˜ ê¸€ë¨¸ë¦¬í‘œ ì—†ì´ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ìœ¼ë¡œë§Œ êµ¬ì„±í•˜ì„¸ìš”
- ì ì ˆí•œ ì´ëª¨ì§€ë¡œ í¥ë¯¸ë¥¼ ë”í•´ì£¼ì„¸ìš”.

ğŸ“š ë‘ ê°€ì§€ ë²„ì „ ìš”êµ¬ì‚¬í•­

**ê°„ë‹¨ ë²„ì „ (Simple)**
- ëŒ€ìƒ: ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€
- ê¸¸ì´: 250-350ì (ëª¨ë°”ì¼ì—ì„œ ì½ê¸° ì¢‹ì€ ê¸¸ì´)
- íŠ¹ì§•: í•µì‹¬ë§Œ ê°„ì¶”ë ¤ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” "ì˜¤ëŠ˜ì˜ í•œ ì… ì—­ì‚¬"
- ì‹œì‘: ë‚ ì§œì™€ í•¨ê»˜ í¥ë¯¸ë¡œìš´ ì²« ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘

**ìƒì„¸ ë²„ì „ (Detail)**
- ëŒ€ìƒ: ì¤‘ê³ ë“±í•™ìƒ ì´ìƒ ìˆ˜ì¤€
- ê¸¸ì´: 1300-1700ì (ì¶©ë¶„í•œ ë°°ê²½ ì„¤ëª… í¬í•¨)
- êµ¬ì„±: ë°°ê²½ ìƒí™© â†’ ì‚¬ê±´ ì „ê°œ â†’ ê²°ê³¼ì™€ ì˜í–¥ â†’ í˜„ì¬ì  ì˜ë¯¸
- íŠ¹ì§•: ì—­ì‚¬ì  ë§¥ë½ê³¼ ì¸ë¬¼ì˜ ì‹¬ë¦¬ê¹Œì§€ ê¹Šì´ ìˆê²Œ ë‹¤ë£¨ê¸°

ğŸ¯ ì¶œë ¥ í˜•ì‹
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš”:

{{
 "simple": "<ê°„ë‹¨ ë²„ì „ ë‚´ìš©>",
 "detail": "<ìƒì„¸ ë²„ì „ ë‚´ìš©>", 
 "year": "<ì •í™•í•œ ì—°ë„>",
 "related_movies": "<ê´€ë ¨ ì˜í™”ë‚˜ ë“œë¼ë§ˆë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ 3-5ê°œ (ì˜ˆ: ì˜í™”ì œëª©1, ë“œë¼ë§ˆì œëª©2, ì˜í™”ì œëª©3)>"
}}

ğŸ’¡ ì°¸ê³ ì‚¬í•­
- ì •í™•í•œ ì—­ì‚¬ì  ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ë˜, ìŠ¤í† ë¦¬í…”ë§ìœ¼ë¡œ ì¬ë¯¸ìˆê²Œ ì „ë‹¬í•˜ì„¸ìš”
- ë…¼ë€ì´ ìˆëŠ” ì‚¬ê±´ì˜ ê²½ìš° ê· í˜•ì¡íŒ ì‹œê°ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”  
- ê´€ë ¨ ì˜í™”/ë“œë¼ë§ˆëŠ” í•´ë‹¹ ì‚¬ê±´ì´ë‚˜ ì¸ë¬¼ì„ ì§ì ‘ì ìœ¼ë¡œ ë‹¤ë£¬ ì‘í’ˆë“¤ë¡œ ì„ ë³„í•˜ì„¸ìš”
- ê´€ë ¨ ì‘í’ˆì´ ì—†ê±°ë‚˜ ì°¾ê¸° ì–´ë ¤ìš´ ê²½ìš° "ê´€ë ¨ ì‘í’ˆ ì—†ìŒ"ìœ¼ë¡œ ê¸°ì¬í•˜ì„¸ìš”'''

        return prompt

    def _extract_from_text(self, content: str) -> Dict[str, str]:
        """í…ìŠ¤íŠ¸ì—ì„œ simple/detail ì¶”ì¶œ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)"""
        try:
            simple_pattern = r'"simple":\s*"([^"]*(?:\\.[^"]*)*)"'
            detail_pattern = r'"detail":\s*"([^"]*(?:\\.[^"]*)*)"'
            year_pattern = r'"year":\s*"([^"]*)"'
            movie_pattern = r'"related_movies":\s*"([^"]*(?:\\.[^"]*)*)"'

            simple_match = re.search(simple_pattern, content, re.DOTALL)
            detail_match = re.search(detail_pattern, content, re.DOTALL)
            year_match = re.search(year_pattern, content)
            movie_match = re.search(movie_pattern, content, re.DOTALL)

            simple_text = simple_match.group(1) if simple_match else 'ì¶”ì¶œ ì‹¤íŒ¨'
            detail_text = detail_match.group(1) if detail_match else 'ì¶”ì¶œ ì‹¤íŒ¨'
            year_text = year_match.group(1) if year_match else 'ì¶”ì¶œ ì‹¤íŒ¨'
            movie_text = movie_match.group(1) if movie_match else 'ê´€ë ¨ ì‘í’ˆ ì—†ìŒ'

            simple_text = simple_text.replace('\\"', '"').replace('\\n', '\n')
            detail_text = detail_text.replace('\\"', '"').replace('\\n', '\n')
            year_text = year_text.replace('\\"', '"').replace('\\n', '\n')
            movie_text = movie_text.replace('\\"', '"').replace('\\n', '\n')

            return {
                'simple': simple_text,
                'detail': detail_text,
                'year': year_text,
                'related_movies': movie_text,
            }

        except Exception as e:
            print(f"âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                'simple': 'ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨',
                'detail': 'ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨',
                'year': 'ì—°ë„ ì¶”ì¶œ ì‹¤íŒ¨',
                'related_movies': 'ê´€ë ¨ ì‘í’ˆ ì—†ìŒ'
            }

def test_create_batch_input_file():
    """ë°°ì¹˜ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ OpenAI Batch ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")

    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')

    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = OpenAIBatchService(api_key)

    # ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±
    print("\nğŸ“ ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„± ì¤‘...")
    create_batch_input_file(service)


def test_batch_status():
    """ë°°ì¹˜ ìƒíƒœ í™•ì¸ í…ŒìŠ¤íŠ¸"""
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')

    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = OpenAIBatchService(api_key)

    # ì—¬ê¸°ì— ì‹¤ì œ ë°°ì¹˜ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”
    batch_id = "batch_685437e7c1988190bebb1a90ba6f06b8"

    print(f"ğŸ“Š ë°°ì¹˜ {batch_id} ìƒíƒœ í™•ì¸ ì¤‘...")
    status = service.check_batch_status(batch_id)

    if status.get('status') == 'completed':
        print("ğŸ‰ ë°°ì¹˜ ì™„ë£Œ! ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        results = service.download_results(batch_id)

        if results:
            # ê²°ê³¼ ì €ì¥
            saved_file = service.save_processed_results(results)
            print(f"âœ… ì´ {len(results)}ê°œ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ")
    else:
        print(f"\nğŸ“‹ ë°°ì¹˜ ìƒíƒœ ìƒì„¸ ì •ë³´:")
        print("-" * 50)
        print(f"ë°°ì¹˜ ID: {status.get('id', 'N/A')}")
        print(f"ìƒíƒœ: {status.get('status', 'N/A')}")
        print(f"ìƒì„± ì‹œê°„: {status.get('created_at', 'N/A')}")
        print(f"ì™„ë£Œ ì‹œê°„: {status.get('completed_at', 'N/A')}")
        print(f"ì‹¤íŒ¨ ì‹œê°„: {status.get('failed_at', 'N/A')}")
        print(f"ì¶œë ¥ íŒŒì¼ ID: {status.get('output_file_id', 'N/A')}")
        print(f"ì—ëŸ¬ íŒŒì¼ ID: {status.get('error_file_id', 'N/A')}")
        
        # ìš”ì²­ ì¹´ìš´íŠ¸ ì •ë³´
        request_counts = status.get('request_counts', {})
        if request_counts:
            print(f"\nğŸ“Š ìš”ì²­ ì²˜ë¦¬ í˜„í™©:")
            print(f"  ì´ ìš”ì²­ ìˆ˜: {request_counts.get('total', 0)}")
            print(f"  ì™„ë£Œëœ ìš”ì²­: {request_counts.get('completed', 0)}")
            print(f"  ì‹¤íŒ¨í•œ ìš”ì²­: {request_counts.get('failed', 0)}")
            print(f"  ì§„í–‰ë¥ : {request_counts.get('completed', 0)}/{request_counts.get('total', 0)}")
        
        # ë©”íƒ€ë°ì´í„° ì •ë³´
        metadata = status.get('metadata', {})
        if metadata:
            print(f"\nğŸ·ï¸ ë©”íƒ€ë°ì´í„°:")
            for key, value in metadata.items():
                print(f"  {key}: {value}")
        
        print(f"\nâ³ ë°°ì¹˜ê°€ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

def test_batch_service():
    """ë°°ì¹˜ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ OpenAI Batch ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")

    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')

    gpt_4_1_nano = "gpt-4.1-nano-2025-04-14" # ( )
    o4_mini = "o4-mini-2025-04-16"  # ë¹„ìš© íš¨ìœ¨ì  ì¶”ë¡  ëª¨ë¸ (input 1.1, output 4.4)
    model_4_1 = "gpt-4.1-mini-2025-04-14"# ê· í˜• ëª¨ë¸ (input 2, output 8)
    o3 = "o3-2025-04-16"  # ê°€ì¥ ê°•ë ¥í•œ ì¶”ë¡  ëª¨ë¸ (ì¶”ë¡  input 2, output 8)
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = OpenAIBatchService(api_key, model=o4_mini)

    # ë°©ë²• 1: ì „ì²´ í”„ë¡œì„¸ìŠ¤ í•œ ë²ˆì—
    print("\n=== ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ===")
    batch_id = service.process_batch_complete("batchinput.jsonl")

    if batch_id:
        print(f"\në°°ì¹˜ IDê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {batch_id}")
        print("ì´ì œ ì£¼ê¸°ì ìœ¼ë¡œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”:")
        print(f"service.check_batch_status('{batch_id}')")

    # 3. ìƒíƒœ í™•ì¸ (ë‚˜ì¤‘ì— ì‹¤í–‰)
    if batch_id:
        service.check_batch_status(batch_id)


def create_batch_input_file(service: OpenAIBatchService, file_path: str = "batchinput.jsonl"):
    """
    ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±
    
    Args:
        service: OpenAIBatchService ì¸ìŠ¤í„´ìŠ¤
        file_path: ìƒì„±í•  íŒŒì¼ ê²½ë¡œ
    """
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì œëª©ê³¼ ë‚ ì§œ)
    test_data = [
        {"title": "ì—˜ë¦¬ìë² ìŠ¤ 2ì„¸ ì—¬ì™• ëŒ€ê´€ì‹", "date": "06-02"},
        {"title": "1ì°¨ ì•„í¸ì „ìŸ ì´‰ë°œ", "date": "06-03"}
    ]
    
    # ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    existing_lines = []
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                existing_lines = f.readlines()
            print(f"ğŸ“‚ ê¸°ì¡´ íŒŒì¼ ë°œê²¬: {len(existing_lines)}ê°œ ìš”ì²­")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # ìƒˆë¡œìš´ ìš”ì²­ë“¤ ìƒì„±
    new_requests = []
    start_id = len(existing_lines) + 1
    
    for i, data in enumerate(test_data, start_id):
        title = data["title"]
        date = data["date"]
        
        # custom_id ìƒì„± (request-0901 í˜•íƒœ)
        custom_id = f"request-{date.replace('-', '')}"
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_content = service.system_prompt
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±
        user_content = service._create_user_prompt(title, date)
        
        # JSONL í˜•ì‹ìœ¼ë¡œ ìš”ì²­ ìƒì„±
        request = {
            "custom_id": custom_id,
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": service.model,
                "messages": [
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ],
                "max_tokens": 2000
            }
        }
        
        new_requests.append(request)
        print(f"ğŸ“ ìš”ì²­ ìƒì„±: {custom_id} - {title}")
    
    # íŒŒì¼ì— ì“°ê¸° (ê¸°ì¡´ ë‚´ìš© + ìƒˆë¡œìš´ ë‚´ìš©)
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            # ê¸°ì¡´ ë‚´ìš© ì“°ê¸°
            for line in existing_lines:
                f.write(line)
            
            # ìƒˆë¡œìš´ ë‚´ìš© ì“°ê¸°
            for request in new_requests:
                f.write(json.dumps(request, ensure_ascii=False) + '\n')
        
        total_requests = len(existing_lines) + len(new_requests)
        print(f"âœ… ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„± ì™„ë£Œ: {file_path}")
        print(f"   - ê¸°ì¡´ ìš”ì²­: {len(existing_lines)}ê°œ")
        print(f"   - ìƒˆ ìš”ì²­: {len(new_requests)}ê°œ")
        print(f"   - ì´ ìš”ì²­: {total_requests}ê°œ")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")


def check_existing_batch():
    """ê¸°ì¡´ ë°°ì¹˜ ìƒíƒœ í™•ì¸ ì˜ˆì œ"""
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    service = OpenAIBatchService(api_key)

    # ì—¬ê¸°ì— ì‹¤ì œ ë°°ì¹˜ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”
    batch_id = "batch_YOUR_BATCH_ID_HERE"

    print(f"ğŸ“Š ë°°ì¹˜ {batch_id} ìƒíƒœ í™•ì¸ ì¤‘...")
    status = service.check_batch_status(batch_id)

    if status.get('status') == 'completed':
        print("ğŸ‰ ë°°ì¹˜ ì™„ë£Œ! ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        results = service.download_results(batch_id)

        if results:
            # ê²°ê³¼ ì €ì¥
            saved_file = service.save_processed_results(results)
            print(f"âœ… ì´ {len(results)}ê°œ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ")


if __name__ == "__main__":
    test_create_batch_input_file()
    # test_batch_service()
    # test_batch_status()