# batch_file_generator.py
"""
ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
Single Responsibility Principle: ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±ë§Œ ë‹´ë‹¹
"""

import json
import os
import argparse
from openai_batch_service import OpenAIBatchService
from dotenv import load_dotenv


def create_batch_input_file(service: OpenAIBatchService, test_data: dict, file_path: str = "batchinput.jsonl"):
    """
    ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±
    
    Args:
        service: OpenAIBatchService ì¸ìŠ¤í„´ìŠ¤
        test_data: ì²˜ë¦¬í•  ë°ì´í„° ë”•ì…”ë„ˆë¦¬ (í‚¤: ë‚ ì§œ, ê°’: ì´ë²¤íŠ¸ ì •ë³´)
        file_path: ìƒì„±í•  íŒŒì¼ ê²½ë¡œ
    """
    # ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    existing_lines = []
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                existing_lines = f.readlines()
            print(f"ğŸ“‚ ê¸°ì¡´ íŒŒì¼ ë°œê²¬: {len(existing_lines)}ê°œ ìš”ì²­")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # ìƒˆë¡œìš´ ìš”ì²­ë“¤ ìƒì„±
    new_requests = []
    
    # ê°ì²´ì˜ í‚¤ê°’ë“¤ì„ ìˆœíšŒ
    for date_key, event_data in test_data.items():
        title = event_data["title"]
        date = event_data["id"]
        
        # custom_id ìƒì„± (06-02 í˜•íƒœ)
        custom_id = f"{date}"
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_content = service.system_prompt
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±
        user_content = service._create_user_prompt(title, date)
        
        # JSONL í˜•ì‹ìœ¼ë¡œ ìš”ì²­ ìƒì„±
        request = {
            "custom_id": custom_id,
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": service.model,
                "messages": [
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ],
                "max_tokens": 2000
            }
        }
        
        new_requests.append(request)
        print(f"ğŸ“ ìš”ì²­ ìƒì„±: {custom_id} - {title}")
    
    # íŒŒì¼ì— ì“°ê¸° (ê¸°ì¡´ ë‚´ìš© + ìƒˆë¡œìš´ ë‚´ìš©)
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            # ê¸°ì¡´ ë‚´ìš© ì“°ê¸°
            for line in existing_lines:
                f.write(line)
            
            # ìƒˆë¡œìš´ ë‚´ìš© ì“°ê¸°
            for request in new_requests:
                f.write(json.dumps(request, ensure_ascii=False) + '\n')
        
        total_requests = len(existing_lines) + len(new_requests)
        print(f"âœ… ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„± ì™„ë£Œ: {file_path}")
        print(f"   - ê¸°ì¡´ ìš”ì²­: {len(existing_lines)}ê°œ")
        print(f"   - ìƒˆ ìš”ì²­: {len(new_requests)}ê°œ")
        print(f"   - ì´ ìš”ì²­: {total_requests}ê°œ")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")


def generate_batch_file(model: str = "gpt-4.1-2025-04-14", data_file: str = "historical_events (3).json"):
    """
    ë°°ì¹˜ íŒŒì¼ ìƒì„± ë©”ì¸ í•¨ìˆ˜
    
    Args:
        model: ì‚¬ìš©í•  ëª¨ë¸ëª…
        data_file: ì½ì–´ì˜¬ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    """
    print("ğŸ“ ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±ê¸°")
    print("=" * 50)
    
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° íŒŒì¼ ë¡œë“œ
    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            test_data = json.load(f)
        print(f"ğŸ“‚ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {data_file} ({len(test_data)}ê°œ í•­ëª©)")
    except FileNotFoundError:
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_file}")
        return
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜: {e}")
        return
    except Exception as e:
        print(f"âŒ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ëª¨ë¸ëª… ì „ë‹¬)
    service = OpenAIBatchService(api_key, model=model)
    
    print(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {model}")
    
    # ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±
    create_batch_input_file(service, test_data)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±')
    parser.add_argument('--model', 
                       default="gpt-4.1-2025-04-14",
                       help='ì‚¬ìš©í•  ëª¨ë¸ëª… (ê¸°ë³¸ê°’: gpt-4.1-2025-04-14)')
    parser.add_argument('--data-file',
                       default="historical_events.json",
                       help='ì½ì–´ì˜¬ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: historical_events.json)')
    
    args = parser.parse_args()
    
    generate_batch_file(args.model, args.data_file)


if __name__ == "__main__":
    main() 