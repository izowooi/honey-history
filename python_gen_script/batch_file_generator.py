# batch_file_generator.py
"""
ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
Single Responsibility Principle: ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±ë§Œ ë‹´ë‹¹
"""

import json
import os
from openai_batch_service import OpenAIBatchService
from dotenv import load_dotenv


def create_batch_input_file(service: OpenAIBatchService, file_path: str = "batchinput.jsonl"):
    """
    ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±
    
    Args:
        service: OpenAIBatchService ì¸ìŠ¤í„´ìŠ¤
        file_path: ìƒì„±í•  íŒŒì¼ ê²½ë¡œ
    """
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì œëª©ê³¼ ë‚ ì§œ)
    test_data = [
        {"title": "ì—˜ë¦¬ìë² ìŠ¤ 2ì„¸ ì—¬ì™• ëŒ€ê´€ì‹", "date": "06-02"},
        {"title": "1ì°¨ ì•„í¸ì „ìŸ ì´‰ë°œ", "date": "06-03"}
    ]
    
    # ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    existing_lines = []
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                existing_lines = f.readlines()
            print(f"ğŸ“‚ ê¸°ì¡´ íŒŒì¼ ë°œê²¬: {len(existing_lines)}ê°œ ìš”ì²­")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # ìƒˆë¡œìš´ ìš”ì²­ë“¤ ìƒì„±
    new_requests = []
    start_id = len(existing_lines) + 1
    
    for i, data in enumerate(test_data, start_id):
        title = data["title"]
        date = data["date"]
        
        # custom_id ìƒì„± (request-0901 í˜•íƒœ)
        custom_id = f"request-{date.replace('-', '')}"
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_content = service.system_prompt
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±
        user_content = service._create_user_prompt(title, date)
        
        # JSONL í˜•ì‹ìœ¼ë¡œ ìš”ì²­ ìƒì„±
        request = {
            "custom_id": custom_id,
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": service.model,
                "messages": [
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ],
                "max_tokens": 2000
            }
        }
        
        new_requests.append(request)
        print(f"ğŸ“ ìš”ì²­ ìƒì„±: {custom_id} - {title}")
    
    # íŒŒì¼ì— ì“°ê¸° (ê¸°ì¡´ ë‚´ìš© + ìƒˆë¡œìš´ ë‚´ìš©)
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            # ê¸°ì¡´ ë‚´ìš© ì“°ê¸°
            for line in existing_lines:
                f.write(line)
            
            # ìƒˆë¡œìš´ ë‚´ìš© ì“°ê¸°
            for request in new_requests:
                f.write(json.dumps(request, ensure_ascii=False) + '\n')
        
        total_requests = len(existing_lines) + len(new_requests)
        print(f"âœ… ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„± ì™„ë£Œ: {file_path}")
        print(f"   - ê¸°ì¡´ ìš”ì²­: {len(existing_lines)}ê°œ")
        print(f"   - ìƒˆ ìš”ì²­: {len(new_requests)}ê°œ")
        print(f"   - ì´ ìš”ì²­: {total_requests}ê°œ")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ“ ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±ê¸°")
    print("=" * 50)
    
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = OpenAIBatchService(api_key)
    
    # ë°°ì¹˜ ì…ë ¥ íŒŒì¼ ìƒì„±
    create_batch_input_file(service)


if __name__ == "__main__":
    main() 